import sys
import os
import time
import torch
from PyQt5.QtWidgets import (
    QApplication,
    QWidget,
    QVBoxLayout,
    QHBoxLayout,
    QLabel,
    QMessageBox,
    QFileDialog,
    QFrame,
)
from PyQt5.QtCore import Qt
from utils.ui import InfoShowWidget, AirBtn, FileSelector


class InferenceInterface(QWidget):
    def __init__(self):
        super().__init__()
        self.initUI()

    def initUI(self):
        self.setWindowTitle("Inference Interface")

        # Set window size to 2/3 of the screen and center it
        screen = QApplication.desktop().screenGeometry()
        width, height = screen.width() * 2 // 3, screen.height() * 2 // 3
        self.setGeometry(
            (screen.width() - width) // 2,
            (screen.height() - height) // 2,
            width,
            height,
        )

        # Layouts
        main_layout = QVBoxLayout()
        model_input_layout = QHBoxLayout()
        result_show_layout = QVBoxLayout()

        # First Module: Input Parameters
        self.ckp_selector = FileSelector(
            selector_text="未选择模型文件:",
            btn_text="选择",
            filetype="PyTorch Model Files (*.pth)",
        )
        load_model_button = AirBtn(
            "加载", fixed_size=(100, 50), background_color="#13a460"
        )
        load_model_button.clicked.connect(self.load_model)

        self.audio_file_selector = FileSelector(
            selector_text="未选择音频文件:",
            btn_text="选择",
            filetype="Audio Files (*.wav)",
        )
        audio_enhance_button = AirBtn(
            "降噪", fixed_size=(100, 50), background_color="#13a460"
        )
        audio_enhance_button.clicked.connect(self.audio_enhance)

        model_input_layout.addWidget(self.ckp_selector)
        model_input_layout.addWidget(load_model_button)
        model_input_layout.addWidget(self.audio_file_selector)
        model_input_layout.addWidget(audio_enhance_button)

        # Add a line separator
        line1 = QFrame()
        line1.setFrameShape(QFrame.HLine)
        line1.setFrameShadow(QFrame.Sunken)

        # Second Module: Result Show

        # Add a line separator

        self.result_sisnr_widget = InfoShowWidget(
            info_label="si-SNR", label_bg_color="#000000"
        )
        self.result_time_widget = InfoShowWidget(
            info_label="耗时", label_bg_color="#000000"
        )

        first_line = QHBoxLayout()
        first_line.addWidget(self.result_sisnr_widget)
        first_line.addStretch()
        first_line.addWidget(self.result_time_widget)

        self.res_output_path_widget = InfoShowWidget(
            info_label="输出文件", label_bg_color="#000000"
        )

        second_line = QHBoxLayout()
        second_line.addWidget(self.res_output_path_widget)

        result_show_layout = QVBoxLayout()
        result_show_layout.setAlignment(Qt.AlignCenter)
        result_show_layout.addLayout(first_line)
        result_show_layout.addLayout(second_line)

        # Add layouts to main layout
        main_layout.addStretch()
        main_layout.addLayout(model_input_layout)
        main_layout.addStretch()
        main_layout.addWidget(line1)
        main_layout.addLayout(result_show_layout)
        main_layout.addStretch()
        self.setLayout(main_layout)
        # Initialize model and device
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

    def load_model(self):
        config_file = "configs/pretrain.yml"
        checkpoint = self.ckp_selector.get_selected_file()
        if not config_file or not checkpoint:
            QMessageBox.critical(self, "错误", "请提供模型文件路径")
            return

        self.model = torch.load(checkpoint)
        self.model.to(self.device)
        self.model.eval()

        QMessageBox.information(self, "提示", "模型加载成功")

    def audio_enhance(self):
        self.audio_input_path = self.audio_file_selector.get_selected_file()
        if not self.model:
            QMessageBox.critical(self, "错误", "请先加载模型")
            return

        if not self.audio_input_path:
            QMessageBox.critical(self, "错误", "请先选择音频")
            return

        # enhance audio
        # show si-snr
        # show time cost
        # show output path
        QMessageBox.information(self, "提示", "降噪完毕！")


if __name__ == "__main__":
    os.chdir(r"C:\Users\june\Workspace\Asteroid\code")
    app = QApplication(sys.argv)
    main_window = InferenceInterface()
    main_window.show()
    sys.exit(app.exec_())
